{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f7f43a-64b8-46c0-895d-a9456eda88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bfa8661-6aec-42cd-87e2-83abdd838e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义常量和超常数\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "NOISE_RATIO = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4299e149-78ac-4af3-86c2-5118f9d76e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数来加载数据集和添加噪声\n",
    "def load_dataset(noise_ratio):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # 添加噪声\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    noise_labels = np.random.choice(num_classes, int(len(train_dataset.targets) * noise_ratio), replace=True)\n",
    "    for idx, label in zip(noise_labels, train_dataset.targets):\n",
    "        if random.random() < (0.2 / (num_classes - 1)):\n",
    "            new_label = random.randint(0, num_classes - 1)\n",
    "            while new_label == label:\n",
    "                new_label = random.randint(0, num_classes - 1)\n",
    "            train_dataset.targets[idx] = new_label\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c0ce94c-9275-4b98-89db-dcd4b807aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义噪声过滤网络的结构\n",
    "class NoiseFilterNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NoiseFilterNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn4(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    #定义训练函数\n",
    "    def train_model(self, train_loader, optimizer, criterion):\n",
    "        self.train()\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = self(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_acc += (predicted == target).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc /= len(train_loader.dataset)\n",
    "\n",
    "        return train_loss, train_acc\n",
    "\n",
    "    def test_model(self, test_loader, criterion):\n",
    "        self.eval()\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                output = self(data)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                test_acc += (predicted == target).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_acc /= len(test_loader.dataset)\n",
    "\n",
    "        return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4098f37-9944-4a68-8dee-072637785bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/ma-user/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504c5069dde44a34b81c78fb4022cee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.0196, Train Acc: 0.5508, Test Loss: 0.0165, Test Acc: 0.6273\n",
      "Epoch [2/100], Train Loss: 0.0143, Train Acc: 0.6761, Test Loss: 0.0137, Test Acc: 0.6950\n",
      "Epoch [3/100], Train Loss: 0.0125, Train Acc: 0.7182, Test Loss: 0.0134, Test Acc: 0.6943\n",
      "Epoch [4/100], Train Loss: 0.0113, Train Acc: 0.7473, Test Loss: 0.0116, Test Acc: 0.7429\n",
      "Epoch [5/100], Train Loss: 0.0106, Train Acc: 0.7620, Test Loss: 0.0118, Test Acc: 0.7458\n",
      "Epoch [6/100], Train Loss: 0.0098, Train Acc: 0.7806, Test Loss: 0.0105, Test Acc: 0.7709\n",
      "Epoch [7/100], Train Loss: 0.0092, Train Acc: 0.7961, Test Loss: 0.0100, Test Acc: 0.7780\n",
      "Epoch [8/100], Train Loss: 0.0087, Train Acc: 0.8053, Test Loss: 0.0095, Test Acc: 0.7901\n",
      "Epoch [9/100], Train Loss: 0.0083, Train Acc: 0.8164, Test Loss: 0.0093, Test Acc: 0.7927\n",
      "Epoch [10/100], Train Loss: 0.0080, Train Acc: 0.8213, Test Loss: 0.0090, Test Acc: 0.8011\n",
      "Epoch [11/100], Train Loss: 0.0075, Train Acc: 0.8313, Test Loss: 0.0095, Test Acc: 0.7900\n",
      "Epoch [12/100], Train Loss: 0.0073, Train Acc: 0.8347, Test Loss: 0.0089, Test Acc: 0.8039\n",
      "Epoch [13/100], Train Loss: 0.0071, Train Acc: 0.8415, Test Loss: 0.0084, Test Acc: 0.8142\n",
      "Epoch [14/100], Train Loss: 0.0068, Train Acc: 0.8500, Test Loss: 0.0085, Test Acc: 0.8131\n",
      "Epoch [15/100], Train Loss: 0.0065, Train Acc: 0.8543, Test Loss: 0.0090, Test Acc: 0.8131\n",
      "Epoch [16/100], Train Loss: 0.0063, Train Acc: 0.8595, Test Loss: 0.0080, Test Acc: 0.8228\n",
      "Epoch [17/100], Train Loss: 0.0062, Train Acc: 0.8617, Test Loss: 0.0082, Test Acc: 0.8209\n",
      "Epoch [18/100], Train Loss: 0.0060, Train Acc: 0.8682, Test Loss: 0.0082, Test Acc: 0.8241\n",
      "Epoch [19/100], Train Loss: 0.0057, Train Acc: 0.8723, Test Loss: 0.0081, Test Acc: 0.8247\n",
      "Epoch [20/100], Train Loss: 0.0055, Train Acc: 0.8748, Test Loss: 0.0082, Test Acc: 0.8245\n",
      "Epoch [21/100], Train Loss: 0.0054, Train Acc: 0.8802, Test Loss: 0.0079, Test Acc: 0.8285\n",
      "Epoch [22/100], Train Loss: 0.0052, Train Acc: 0.8830, Test Loss: 0.0079, Test Acc: 0.8303\n",
      "Epoch [23/100], Train Loss: 0.0052, Train Acc: 0.8842, Test Loss: 0.0084, Test Acc: 0.8261\n",
      "Epoch [24/100], Train Loss: 0.0050, Train Acc: 0.8856, Test Loss: 0.0077, Test Acc: 0.8328\n",
      "Epoch [25/100], Train Loss: 0.0048, Train Acc: 0.8924, Test Loss: 0.0078, Test Acc: 0.8349\n",
      "Epoch [26/100], Train Loss: 0.0047, Train Acc: 0.8943, Test Loss: 0.0077, Test Acc: 0.8377\n",
      "Epoch [27/100], Train Loss: 0.0046, Train Acc: 0.8968, Test Loss: 0.0077, Test Acc: 0.8376\n",
      "Epoch [28/100], Train Loss: 0.0045, Train Acc: 0.8992, Test Loss: 0.0078, Test Acc: 0.8412\n",
      "Epoch [29/100], Train Loss: 0.0045, Train Acc: 0.8998, Test Loss: 0.0078, Test Acc: 0.8392\n",
      "Epoch [30/100], Train Loss: 0.0043, Train Acc: 0.9033, Test Loss: 0.0082, Test Acc: 0.8329\n",
      "Epoch [31/100], Train Loss: 0.0042, Train Acc: 0.9069, Test Loss: 0.0078, Test Acc: 0.8405\n",
      "Epoch [32/100], Train Loss: 0.0041, Train Acc: 0.9083, Test Loss: 0.0078, Test Acc: 0.8407\n",
      "Epoch [33/100], Train Loss: 0.0040, Train Acc: 0.9094, Test Loss: 0.0077, Test Acc: 0.8403\n",
      "Epoch [34/100], Train Loss: 0.0040, Train Acc: 0.9109, Test Loss: 0.0078, Test Acc: 0.8467\n",
      "Epoch [35/100], Train Loss: 0.0038, Train Acc: 0.9148, Test Loss: 0.0080, Test Acc: 0.8385\n",
      "Epoch [36/100], Train Loss: 0.0037, Train Acc: 0.9151, Test Loss: 0.0077, Test Acc: 0.8469\n",
      "Epoch [37/100], Train Loss: 0.0036, Train Acc: 0.9166, Test Loss: 0.0080, Test Acc: 0.8447\n",
      "Epoch [38/100], Train Loss: 0.0035, Train Acc: 0.9211, Test Loss: 0.0077, Test Acc: 0.8477\n",
      "Epoch [39/100], Train Loss: 0.0035, Train Acc: 0.9211, Test Loss: 0.0084, Test Acc: 0.8352\n",
      "Epoch [40/100], Train Loss: 0.0035, Train Acc: 0.9198, Test Loss: 0.0078, Test Acc: 0.8419\n",
      "Epoch [41/100], Train Loss: 0.0034, Train Acc: 0.9230, Test Loss: 0.0079, Test Acc: 0.8424\n",
      "Epoch [42/100], Train Loss: 0.0033, Train Acc: 0.9243, Test Loss: 0.0083, Test Acc: 0.8339\n",
      "Epoch [43/100], Train Loss: 0.0033, Train Acc: 0.9254, Test Loss: 0.0082, Test Acc: 0.8424\n",
      "Epoch [44/100], Train Loss: 0.0032, Train Acc: 0.9296, Test Loss: 0.0081, Test Acc: 0.8470\n",
      "Epoch [45/100], Train Loss: 0.0031, Train Acc: 0.9291, Test Loss: 0.0083, Test Acc: 0.8400\n",
      "Epoch [46/100], Train Loss: 0.0032, Train Acc: 0.9274, Test Loss: 0.0078, Test Acc: 0.8465\n",
      "Epoch [47/100], Train Loss: 0.0030, Train Acc: 0.9311, Test Loss: 0.0080, Test Acc: 0.8491\n",
      "Epoch [48/100], Train Loss: 0.0030, Train Acc: 0.9318, Test Loss: 0.0080, Test Acc: 0.8491\n",
      "Epoch [49/100], Train Loss: 0.0030, Train Acc: 0.9319, Test Loss: 0.0082, Test Acc: 0.8446\n",
      "Epoch [50/100], Train Loss: 0.0029, Train Acc: 0.9332, Test Loss: 0.0081, Test Acc: 0.8484\n",
      "Epoch [51/100], Train Loss: 0.0028, Train Acc: 0.9359, Test Loss: 0.0079, Test Acc: 0.8525\n",
      "Epoch [52/100], Train Loss: 0.0028, Train Acc: 0.9361, Test Loss: 0.0079, Test Acc: 0.8540\n",
      "Epoch [53/100], Train Loss: 0.0027, Train Acc: 0.9387, Test Loss: 0.0084, Test Acc: 0.8411\n",
      "Epoch [54/100], Train Loss: 0.0027, Train Acc: 0.9373, Test Loss: 0.0083, Test Acc: 0.8469\n",
      "Epoch [55/100], Train Loss: 0.0028, Train Acc: 0.9377, Test Loss: 0.0085, Test Acc: 0.8423\n",
      "Epoch [56/100], Train Loss: 0.0027, Train Acc: 0.9394, Test Loss: 0.0081, Test Acc: 0.8495\n",
      "Epoch [57/100], Train Loss: 0.0026, Train Acc: 0.9405, Test Loss: 0.0082, Test Acc: 0.8482\n",
      "Epoch [58/100], Train Loss: 0.0026, Train Acc: 0.9416, Test Loss: 0.0085, Test Acc: 0.8454\n",
      "Epoch [59/100], Train Loss: 0.0026, Train Acc: 0.9430, Test Loss: 0.0086, Test Acc: 0.8410\n",
      "Epoch [60/100], Train Loss: 0.0026, Train Acc: 0.9424, Test Loss: 0.0086, Test Acc: 0.8423\n",
      "Epoch [61/100], Train Loss: 0.0025, Train Acc: 0.9448, Test Loss: 0.0083, Test Acc: 0.8502\n",
      "Epoch [62/100], Train Loss: 0.0025, Train Acc: 0.9437, Test Loss: 0.0084, Test Acc: 0.8501\n",
      "Epoch [63/100], Train Loss: 0.0025, Train Acc: 0.9446, Test Loss: 0.0088, Test Acc: 0.8418\n",
      "Epoch [64/100], Train Loss: 0.0023, Train Acc: 0.9496, Test Loss: 0.0084, Test Acc: 0.8464\n",
      "Epoch [65/100], Train Loss: 0.0023, Train Acc: 0.9492, Test Loss: 0.0086, Test Acc: 0.8471\n",
      "Epoch [66/100], Train Loss: 0.0024, Train Acc: 0.9457, Test Loss: 0.0081, Test Acc: 0.8582\n",
      "Epoch [67/100], Train Loss: 0.0024, Train Acc: 0.9472, Test Loss: 0.0084, Test Acc: 0.8470\n",
      "Epoch [68/100], Train Loss: 0.0022, Train Acc: 0.9496, Test Loss: 0.0090, Test Acc: 0.8447\n",
      "Epoch [69/100], Train Loss: 0.0023, Train Acc: 0.9485, Test Loss: 0.0084, Test Acc: 0.8511\n",
      "Epoch [70/100], Train Loss: 0.0022, Train Acc: 0.9499, Test Loss: 0.0085, Test Acc: 0.8528\n",
      "Epoch [71/100], Train Loss: 0.0021, Train Acc: 0.9524, Test Loss: 0.0084, Test Acc: 0.8515\n",
      "Epoch [72/100], Train Loss: 0.0021, Train Acc: 0.9524, Test Loss: 0.0088, Test Acc: 0.8433\n",
      "Epoch [73/100], Train Loss: 0.0021, Train Acc: 0.9521, Test Loss: 0.0085, Test Acc: 0.8506\n",
      "Epoch [74/100], Train Loss: 0.0022, Train Acc: 0.9504, Test Loss: 0.0086, Test Acc: 0.8521\n",
      "Epoch [75/100], Train Loss: 0.0021, Train Acc: 0.9527, Test Loss: 0.0089, Test Acc: 0.8467\n",
      "Epoch [76/100], Train Loss: 0.0021, Train Acc: 0.9534, Test Loss: 0.0086, Test Acc: 0.8528\n",
      "Epoch [77/100], Train Loss: 0.0021, Train Acc: 0.9532, Test Loss: 0.0089, Test Acc: 0.8460\n",
      "Epoch [78/100], Train Loss: 0.0020, Train Acc: 0.9538, Test Loss: 0.0088, Test Acc: 0.8484\n",
      "Epoch [79/100], Train Loss: 0.0020, Train Acc: 0.9550, Test Loss: 0.0087, Test Acc: 0.8544\n",
      "Epoch [80/100], Train Loss: 0.0020, Train Acc: 0.9547, Test Loss: 0.0090, Test Acc: 0.8515\n",
      "Epoch [81/100], Train Loss: 0.0020, Train Acc: 0.9555, Test Loss: 0.0090, Test Acc: 0.8437\n",
      "Epoch [82/100], Train Loss: 0.0019, Train Acc: 0.9578, Test Loss: 0.0090, Test Acc: 0.8502\n",
      "Epoch [83/100], Train Loss: 0.0018, Train Acc: 0.9586, Test Loss: 0.0090, Test Acc: 0.8497\n",
      "Epoch [84/100], Train Loss: 0.0019, Train Acc: 0.9574, Test Loss: 0.0088, Test Acc: 0.8471\n",
      "Epoch [85/100], Train Loss: 0.0019, Train Acc: 0.9584, Test Loss: 0.0087, Test Acc: 0.8494\n",
      "Epoch [86/100], Train Loss: 0.0019, Train Acc: 0.9571, Test Loss: 0.0090, Test Acc: 0.8472\n",
      "Epoch [87/100], Train Loss: 0.0018, Train Acc: 0.9598, Test Loss: 0.0090, Test Acc: 0.8537\n",
      "Epoch [88/100], Train Loss: 0.0018, Train Acc: 0.9596, Test Loss: 0.0088, Test Acc: 0.8530\n",
      "Epoch [89/100], Train Loss: 0.0018, Train Acc: 0.9582, Test Loss: 0.0092, Test Acc: 0.8500\n",
      "Epoch [90/100], Train Loss: 0.0018, Train Acc: 0.9590, Test Loss: 0.0087, Test Acc: 0.8550\n",
      "Epoch [91/100], Train Loss: 0.0017, Train Acc: 0.9598, Test Loss: 0.0090, Test Acc: 0.8558\n",
      "Epoch [92/100], Train Loss: 0.0017, Train Acc: 0.9602, Test Loss: 0.0088, Test Acc: 0.8503\n",
      "Epoch [93/100], Train Loss: 0.0017, Train Acc: 0.9610, Test Loss: 0.0087, Test Acc: 0.8584\n",
      "Epoch [94/100], Train Loss: 0.0018, Train Acc: 0.9581, Test Loss: 0.0091, Test Acc: 0.8476\n",
      "Epoch [95/100], Train Loss: 0.0017, Train Acc: 0.9631, Test Loss: 0.0088, Test Acc: 0.8550\n",
      "Epoch [96/100], Train Loss: 0.0017, Train Acc: 0.9617, Test Loss: 0.0092, Test Acc: 0.8511\n",
      "Epoch [97/100], Train Loss: 0.0017, Train Acc: 0.9604, Test Loss: 0.0090, Test Acc: 0.8546\n",
      "Epoch [98/100], Train Loss: 0.0017, Train Acc: 0.9618, Test Loss: 0.0094, Test Acc: 0.8535\n",
      "Epoch [99/100], Train Loss: 0.0017, Train Acc: 0.9625, Test Loss: 0.0092, Test Acc: 0.8537\n",
      "Epoch [100/100], Train Loss: 0.0016, Train Acc: 0.9632, Test Loss: 0.0094, Test Acc: 0.8514\n",
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 加载数据集并添加噪声\n",
    "    train_loader, test_loader = load_dataset(NOISE_RATIO)\n",
    "    \n",
    "    # 创建ResNet-18作为backbone\n",
    "    backbone = models.resnet18(pretrained=True)\n",
    "    backbone.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "    \n",
    "    # 创建模型并将其移动到GPU上\n",
    "    model = NoiseFilterNet().cuda()\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # 训练和测试模型\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = model.train_model(train_loader, optimizer, criterion)\n",
    "        test_loss, test_acc = model.test_model(test_loader, criterion)\n",
    "\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.4f}'\n",
    "              .format(epoch + 1, EPOCHS, train_loss, train_acc, test_loss, test_acc))\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), 'noise_filter_net.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    \n",
    "    return acc\n",
    "if os.path.exists('noise_filter_net.pth'):\n",
    "    print(\"File saved successfully.\")\n",
    "else:\n",
    "    print(\"Failed to save the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be92fecb-0566-4127-a836-0cf11ec6d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Test Accuracy: 85.59%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    # 加载测试集\n",
    "    _, test_loader = load_dataset(NOISE_RATIO)\n",
    "\n",
    "    # 加载模型并进行测试\n",
    "    model = NoiseFilterNet().cuda()\n",
    "    model.load_state_dict(torch.load('noise_filter_net.pth'))\n",
    "    test_acc = evaluate(model, test_loader)\n",
    "\n",
    "    print('Test Accuracy: {:.2f}%'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1818a7cf32131e9ad82e08d0c725acdbfedf88956d469e5aa89927950633eefd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
